[vocab]
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path to the training set image names
train_path = ./dataset/Flickr_8k.trainImages.txt
;path to where vocab .pkl file is to be saved
vocab_path = ./vocab.pkl
;minimum word frequency threshold
threshold = 1

[train]
;path for saving trained models
model_path = ./trained_models/
;path for vocabulary wrapper
vocab_path = ./vocab.pkl
;directory for images
image_dir = ./dataset/Flickr8k_Dataset
;path for caption file
caption_path = ./dataset/Flickr8k.token.txt
;path for train split file'
train_path = ./dataset/Flickr_8k.trainImages.txt
;path for validation split file
val_path = ./dataset/Flickr_8k.testImages.txt
;input image size for particular pretrained CNN (244/244/299)
image_size = 244
;step size for printing log info
log_step = 20
;step size for saving trained models
save_step = 1000

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512,192) 2048 for panoptic
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False

;number of epochs
num_epochs = 10
;batch size
batch_size = 32
;number of parallel workers during training
num_workers = 4
;learning rate for optimizer
learning_rate = 0.0005

[eval]
;path for trained encoder
encoder_path = ./trained_models/encoder-3.ckpt
;path for trained decoder
decoder_path = ./trained_models/decoder-3.ckpt
;path to vocabulary wrapper
vocab_path = ./vocab.pkl
;path to dataset images
image_dir = ./dataset/Flickr8k_Dataset
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path for val split file
val_path = ./dataset/Flickr_8k.devImages.txt
;input image size for particular pretrained CNN
image_size = 244

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512)
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False
;batch size
batch_size = 1
;number of parallel workers during training
num_workers = 0

[sample]
;path for trained encoder
encoder_path = ./trained_models/encoder-3.ckpt
;path for trained decoder
decoder_path = ./trained_models/decoder-3.ckpt
;path to vocabulary wrapper
vocab_path = ./vocab.pkl
;path to dataset images
image_dir = ./dataset/Flickr8k_Dataset
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path for val split file
val_path = ./dataset/Flickr_8k.devImages.txt
;input image size for particular pretrained CNN
image_size = 244

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512)
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False
;batch size
batch_size = 1
;number of parallel workers during training
num_workers = 0

image = ./samples/47871819_db55ac4699.jpg


